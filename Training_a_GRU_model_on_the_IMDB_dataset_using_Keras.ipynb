{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code loads the IMDB dataset from Keras, pads the sequences to a fixed length, builds a GRU model with an embedding layer, trains the model on the data, and evaluates the model on the test set. The model achieves a validation accuracy of around 0.83 after 5 epochs. Note that you may need to adjust the hyperparameters and experiment with different architectures to achieve better performance.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HJZCV8FmKrIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set hyperparameters\n",
        "max_features = 30000  # Number of words to consider as features # define vocab of 30000 words\n",
        "maxlen = 300  # set Max sequence length of each row to 300\n",
        "embedding_size = 128  # Embedding dimension\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences \n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Build GRU model\n",
        "model = keras.Sequential()\n",
        "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
        "model.add(GRU(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=128)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(x_test, y_test, batch_size=128)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVxXlVt2CWLj",
        "outputId": "fc82c5d8-c085-48a8-896e-06176041b2e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "196/196 [==============================] - 271s 1s/step - loss: 0.4730 - accuracy: 0.7591 - val_loss: 0.3755 - val_accuracy: 0.8427\n",
            "Epoch 2/5\n",
            "196/196 [==============================] - 258s 1s/step - loss: 0.2344 - accuracy: 0.9086 - val_loss: 0.3253 - val_accuracy: 0.8701\n",
            "Epoch 3/5\n",
            "196/196 [==============================] - 254s 1s/step - loss: 0.1469 - accuracy: 0.9488 - val_loss: 0.3980 - val_accuracy: 0.8530\n",
            "Epoch 4/5\n",
            "196/196 [==============================] - 255s 1s/step - loss: 0.0915 - accuracy: 0.9692 - val_loss: 0.4669 - val_accuracy: 0.8554\n",
            "Epoch 5/5\n",
            "196/196 [==============================] - 245s 1s/step - loss: 0.0569 - accuracy: 0.9817 - val_loss: 0.4541 - val_accuracy: 0.8378\n",
            "196/196 [==============================] - 15s 79ms/step - loss: 0.4541 - accuracy: 0.8378\n",
            "Test loss: 0.4540673792362213\n",
            "Test accuracy: 0.8378400206565857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to predict sentiment of new review\n",
        "def predict_sentiment(new_review):\n",
        "  # Convert new review to word indices and pad sequence\n",
        "  sequence = keras.preprocessing.text.text_to_word_sequence(new_review)\n",
        "  word_index = imdb.get_word_index()\n",
        "  test_data = [[word_index[word] if word in word_index and word_index[word] < max_features else 0 for word in sequence]]\n",
        "  test_data = pad_sequences(test_data, maxlen=maxlen)\n",
        "  prediction = model.predict(test_data)[0][0]\n",
        "  if prediction >= 0.5: #threshold = 0.5\n",
        "    return 'The sentiment of the input text is Positive'\n",
        "  else:\n",
        "    return 'The sentiment of the input text is Negative'\n",
        "\n",
        "# Test the function\n",
        "reviews = [\"This movie was great!\", \"This movie was horrible and terrible.\", \"This movie was really good. I enjoyed it a lot.\"]\n",
        "for review in reviews:\n",
        "    sentiment = predict_sentiment(review)\n",
        "    print(sentiment)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV7Gor5HH-_S",
        "outputId": "a280740a-e069-48ae-91ef-2e4c5b4537b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 101ms/step\n",
            "The sentiment of the input text is Positive\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "The sentiment of the input text is Negative\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "The sentiment of the input text is Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![alt text](https://i.pinimg.com/originals/44/b2/1c/44b21cbdd640cbb1ae57470151787aac.png)\"\n"
      ],
      "metadata": {
        "id": "ZlsxUobbfVyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "elW1wCGsfXXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}